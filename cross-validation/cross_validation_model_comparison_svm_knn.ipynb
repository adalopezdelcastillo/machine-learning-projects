{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "815a2d68-7a7d-4acd-9393-284a9bd91af3",
   "metadata": {},
   "source": [
    "Ada López del Castillo, 1605347"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31bcb4c-3b97-4cec-ad87-0106e5d3c96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import make_blobs, load_breast_cancer\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split, StratifiedKFold, cross_val_score, cross_validate, GridSearchCV, LeaveOneOut\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, accuracy_score, precision_score, recall_score,\n",
    "    f1_score, matthews_corrcoef, balanced_accuracy_score, roc_auc_score,\n",
    "    RocCurveDisplay\n",
    ")\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Inferència estadística\n",
    "from scipy.stats import shapiro, ttest_rel, wilcoxon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707aef41-d506-4ec2-91df-6060ee8fb3e8",
   "metadata": {},
   "source": [
    "### EXERCICI 1: Split vs k-fold CV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c00e760-8bea-4f1a-9ca3-199878fb03e3",
   "metadata": {},
   "source": [
    "Amb el dataset de Breast Cancer, calcula Accuracy, F1 i MCC amb split (80/20) i amb k-fold CV=10 per a SVM(RBF, C=1) i kNN(k=7). Comenta diferències d’estabilitat i possibles biaixos d’estimació."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ef5c8a-a036-4371-91df-6cfa74251572",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_breast_cancer()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "#Fem split 80/20\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test  = scaler.transform(X_test)\n",
    "\n",
    "#posem KNN=7\n",
    "svm_base = SVC(kernel='rbf', C=1, probability=True, random_state=42).fit(X_train, y_train)\n",
    "knn_base = KNeighborsClassifier(n_neighbors=7).fit(X_train, y_train)\n",
    "\n",
    "yhat_svm = svm_base.predict(X_test)\n",
    "yhat_knn = knn_base.predict(X_test)\n",
    "\n",
    "#Volem l'accuracy, f1 i MCC\n",
    "def metrics_dict(y_true, y_pred):\n",
    "    return dict(\n",
    "        accuracy=accuracy_score(y_true, y_pred),\n",
    "        f1=f1_score(y_true, y_pred),\n",
    "        mcc=matthews_corrcoef(y_true, y_pred)\n",
    "    )\n",
    "\n",
    "print(\"SPLIT 80/20\")\n",
    "print(\"Mètriques hold-out — SVM:\\n\", pd.Series(metrics_dict(y_test, yhat_svm)).round(4))\n",
    "print(\"\\nMètriques hold-out — kNN:\\n\", pd.Series(metrics_dict(y_test, yhat_knn)).round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac5b785-02d9-451f-99ca-8bf96a551456",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ara amb K-fold CV=10\n",
    "\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "pipe_svm = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", SVC(kernel='rbf', C=1, random_state=42))\n",
    "])\n",
    "pipe_knn = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", KNeighborsClassifier(n_neighbors=7))\n",
    "])\n",
    "\n",
    "cv_svm = cross_validate(pipe_svm, X, y, cv=cv, scoring=[\"accuracy\", \"f1\", \"matthews_corrcoef\"])\n",
    "cv_knn = cross_validate(pipe_knn, X, y, cv=cv, scoring=[\"accuracy\", \"f1\", \"matthews_corrcoef\"])\n",
    "\n",
    "print(\"\\nK-fold CV=10:\")\n",
    "print(\"SVM — Accuracy:\", round(cv_svm[\"test_accuracy\"].mean(), 4),\n",
    "      \"f1:\", round(cv_svm[\"test_f1\"].mean(), 4),\n",
    "      \"MCC:\", round(cv_svm[\"test_matthews_corrcoef\"].mean(), 4))\n",
    "print(\"kNN — Accuracy:\", round(cv_knn[\"test_accuracy\"].mean(), 4),\n",
    "      \"f1:\", round(cv_knn[\"test_f1\"].mean(), 4),\n",
    "      \"MCC:\", round(cv_knn[\"test_matthews_corrcoef\"].mean(), 4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5be642e-f991-4604-82f8-d4a664a95bdb",
   "metadata": {},
   "source": [
    "Amb el split 80/20 tenim resultats molt bons en els dos casos, tot i que l'SVM és lleugerament millor que el KNN en totes les mètriques. En el cas de K-fold, el KNN també té valors més baixos que el SVM, i en general són inferiors a les del split.\n",
    "\n",
    "Recordem que Split Validation és un mètode simple i ràpid, però té poca fiabilitat estadística, ja que els valors depenen de la partició aleatòria escollida, si hagués estat una altra, podrien haver sortit unes mètriques diferents.\n",
    "En canvi, el K-fold, que consisteix a dividir en 10 folds en aquest cas, és molt més robust, perquè els valors són la mitjana de 10 particions diferents i per tant, es té en compte tota la variabilitat del conjunt de dades.\n",
    "Per tant, els valors són més estables i representatius.\n",
    "\n",
    "A més, tant en split com en K-fold, el SVM és més robust i té millor rendiment que el KNN.\n",
    "Això ho podem veure clarament en el MCC, que és la mètrica que resumeix el rendiment de manera global."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece7d89f-2dea-4eb3-b0cd-a9baa3716492",
   "metadata": {},
   "source": [
    "### Exercici 2: Comparació aparellada amb test d'hipòtesis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1917a44-1162-4a87-bf60-8d73427ca653",
   "metadata": {},
   "source": [
    "Compara SVM(RBF, C=1) vs kNN(k=7) amb k=10 CV usant F1. Aplica Shapiro-Wilk a la diferència fold a fold i tria el test adequat (t-test aparellat o Wilcoxon). Interpreta el p-valor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9a4fac-ebcb-444a-ae93-8c8446a89f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_pairwise_compare(X, y, model_a, model_b, k=10, scoring=\"f1\", random_state=42):\n",
    "    skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=random_state)\n",
    "    a_scores, b_scores = [], []\n",
    "    for tr, va in skf.split(X, y):\n",
    "        Xtr, Xva = X[tr], X[va]\n",
    "        ytr, yva = y[tr], y[va]\n",
    "        # Escalat dins de cada fold via Pipeline\n",
    "        pipe_a = Pipeline([(\"scaler\", StandardScaler()), (\"clf\", model_a)])\n",
    "        pipe_b = Pipeline([(\"scaler\", StandardScaler()), (\"clf\", model_b)])\n",
    "        pipe_a.fit(Xtr, ytr); pipe_b.fit(Xtr, ytr)\n",
    "        pa = pipe_a.predict(Xva); pb = pipe_b.predict(Xva)\n",
    "        if scoring == \"accuracy\":\n",
    "            sa = accuracy_score(yva, pa); sb = accuracy_score(yva, pb)\n",
    "        elif scoring == \"precision\":\n",
    "            sa = precision_score(yva, pa); sb = precision_score(yva, pb)\n",
    "        elif scoring == \"recall\":\n",
    "            sa = recall_score(yva, pa); sb = recall_score(yva, pb)\n",
    "        elif scoring == \"balanced_accuracy\":\n",
    "            sa = balanced_accuracy_score(yva, pa); sb = balanced_accuracy_score(yva, pb)\n",
    "        elif scoring == \"mcc\":\n",
    "            sa = matthews_corrcoef(yva, pa); sb = matthews_corrcoef(yva, pb)\n",
    "        else:  # default F1\n",
    "            sa = f1_score(yva, pa); sb = f1_score(yva, pb)\n",
    "        a_scores.append(sa); b_scores.append(sb)\n",
    "    a_scores, b_scores = np.array(a_scores), np.array(b_scores)\n",
    "    diff = a_scores - b_scores\n",
    "    result = {\"a_scores\": a_scores, \"b_scores\": b_scores, \"diff\": diff}\n",
    "    sw_p = shapiro(diff).pvalue if len(diff) >= 3 else np.nan\n",
    "    if np.isnan(sw_p) or sw_p < 0.05:\n",
    "        stat, p = wilcoxon(diff, alternative=\"greater\")\n",
    "        test = \"Wilcoxon (no paramètric) sobre diferències\"\n",
    "    else:\n",
    "        stat, p = ttest_rel(a_scores, b_scores, alternative=\"greater\")\n",
    "        test = \"t-test aparellat (H1: model A millor)\"\n",
    "    result.update({\"test\": test, \"stat\": stat, \"pvalue\": p, \"shapiro_p\": sw_p})\n",
    "    return result\n",
    "\n",
    "res = cv_pairwise_compare(\n",
    "    X, y, SVC(kernel='rbf', C=1, random_state=42), KNeighborsClassifier(n_neighbors=7),\n",
    "    k=10, scoring=\"f1\", random_state=7\n",
    ")\n",
    "\n",
    "print(\"Mitjanes F1  — SVM:\", round(res[\"a_scores\"].mean(),4),\n",
    "      \" kNN:\", round(res[\"b_scores\"].mean(),4))\n",
    "print(\"Diferències (SVM−kNN) per fold:\", np.round(res[\"diff\"],4))\n",
    "\n",
    "print(\"\\nTest:\", res[\"test\"])\n",
    "print(\"p-valor:\", res[\"pvalue\"])\n",
    "print(\"Shapiro-Wilk p(normalitat de la diferència):\", res[\"shapiro_p\"])\n",
    "print(\"Interpretació: p<0.05 → evidència que SVM supera kNN en la mètrica escollida.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b44c52-8164-4211-8aa0-fa5a91a5f11b",
   "metadata": {},
   "source": [
    "Pel que fa a mitjanes F1, és millor el SVM, però la diferència és molt petita.\n",
    "En les diferències per fold veiem que són també molt petites, en la majoria de folds la SVM guanya, en la resta, en els que surt 0. hi ha empat i en les que surt en negatiu és que el KNN és superior a SVM.\n",
    "\n",
    "Aplicant el test estadístic Shapiro-Wilk a les diferències, que serveix per comprovar si el conjunt de dades segueix una distribució normal, ha sortit p: 0.01768 < 0.05, per tant, rebutgem la hipòtesi nul·la sobre que segueixen una distribució normal.\n",
    "\n",
    "Si hagués sortit un conjunt de dades amb distribució normal, s'hauria d'escollir el t-test aparellat, Wilcoxon és l'alternativa no paramètrica, és per això que el test escollit ha estat el de Wilcoxon.\n",
    "I ha donat un p-valor de 0.0390625, rebutjant la hipòtesi nul·la, per tant, podem afirmar que SVM supera el kNN en la mètrica escollida, ja que si que hi ha evidència estadistica."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d01ab5-b7d0-4662-a9e4-dc62ba8db2b0",
   "metadata": {},
   "source": [
    "### Exercici 3: Bootstrap d'una mètrica"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7815fbe-739f-4acd-b8d8-36ad8c4a1284",
   "metadata": {},
   "source": [
    "Estima amb bootstrap (B=300) la distribució de MCC per SVM(RBF, C=1) i kNN(k=7) i calcula IC del 95%. Comenta si els intervals es solapen i què implica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd15b814-da9b-44e6-aadc-9150bcfc6060",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_metric(X, y, model, B=300, metric=\"mcc\", random_state=0):\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    n = len(X)\n",
    "    vals = []\n",
    "    for b in range(B):\n",
    "        idx = rng.integers(0, n, size=n)\n",
    "        oob = np.setdiff1d(np.arange(n), np.unique(idx))\n",
    "        if len(oob) == 0:\n",
    "            continue\n",
    "        Xb, yb = X[idx], y[idx]\n",
    "        Xoob, yoob = X[oob], y[oob]\n",
    "        pipe = Pipeline([(\"scaler\", StandardScaler()), (\"clf\", model)])\n",
    "        pipe.fit(Xb, yb)\n",
    "        yp = pipe.predict(Xoob)\n",
    "        if metric == \"mcc\":\n",
    "            v = matthews_corrcoef(yoob, yp)\n",
    "        elif metric == \"f1\":\n",
    "            v = f1_score(yoob, yp)\n",
    "        elif metric == \"accuracy\":\n",
    "            v = accuracy_score(yoob, yp)\n",
    "        else:\n",
    "            raise ValueError(\"Mètrica no suportada\")\n",
    "        vals.append(v)\n",
    "    vals = np.array(vals)\n",
    "    mean = float(np.mean(vals))\n",
    "    ci = tuple(np.quantile(vals, [0.025, 0.975]))\n",
    "    return vals, mean, ci\n",
    "\n",
    "#Models\n",
    "m_svm = SVC(kernel='rbf', C=1, random_state=42)\n",
    "m_knn = KNeighborsClassifier(n_neighbors=7)\n",
    "\n",
    "#Bootstrap MCC de cada model\n",
    "svm_vals, svm_mean, svm_ci = bootstrap_metric(X, y, m_svm, B=300, metric=\"mcc\", random_state=1)\n",
    "knn_vals, knn_mean, knn_ci = bootstrap_metric(X, y, m_knn, B=300, metric=\"mcc\", random_state=1)\n",
    "\n",
    "print(\"SVM — MCC: mitjana\", round(svm_mean,4), \"IC95%\", (round(svm_ci[0],4), round(svm_ci[1],4)))\n",
    "print(\"kNN — MCC: mitjana\", round(knn_mean,4), \"IC95%\", (round(knn_ci[0],4), round(knn_ci[1],4)))\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(svm_vals, bins=20)\n",
    "plt.title(\"Bootstrap MCC — SVM\")\n",
    "plt.xlabel(\"MCC\"); plt.ylabel(\"Freqüència\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(knn_vals, bins=20)\n",
    "plt.title(\"Bootstrap MCC — kNN\")\n",
    "plt.xlabel(\"MCC\"); plt.ylabel(\"Freqüència\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c741849-e797-4702-90c8-8b69f1025ddd",
   "metadata": {},
   "source": [
    "El mètode bootstrap és un model més robust que els anteriors, es crea una mostra aleatòria amb reemplaçament del conjunt original, s'avalua sobre els casos que han quedat fora i es repeteix moltes vegades. D'aquesta manera s'agafa la mitjana de la mètrica, en aquest cas del MCC, i a més ,podem calcular intervals de confiança.\n",
    "\n",
    "Notem que el SVM té una mitja del MCC més alta que el kNN, cosa que no ens sorprèn veient els exercicis anteriors. I tal com podem veure en els histogrammes, en el cas de SVM els valors es concentren sobre el 0.94 i en el KNN en el 0.92.\n",
    "\n",
    "Tot i això, mirant els intervals de confiança, veiem que se solapen. Per tant, tot i que la mitjana hagi estat superior en el SVM, no és estadísticament significant.\n",
    "Ens torna a passar el mateix que abans, amb el bootstrap no podem concloure que SVM sigui millor que KNN en termes de MCC."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a664e8b-98e5-494e-afb2-68291f702b77",
   "metadata": {},
   "source": [
    "### Exercici 4: Dades desequilibrades i mètriques robustes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454ecf1a-4103-42cd-a2cd-7a96e3c6fc8b",
   "metadata": {},
   "source": [
    "Simula dades amb 90% de valors en la classe negativa. Avalua kNN(k=3) i SVM(RBF, C=1) amb Accuracy, Recall (classe minoritària), F1, BA i MCC. Explica la paradoxa de l'accuracy i per què MCC/BA són preferibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04723d93-8169-4fd0-959e-eeff42dde843",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_blobs(\n",
    "    n_samples=1200,\n",
    "    centers=2,\n",
    "    cluster_std=[1.3, 1.3],\n",
    "    n_features=2,\n",
    "    random_state=7\n",
    ")\n",
    "\n",
    "# Generem un vector de classes amb el desequilibri desitjat\n",
    "rng = np.random.default_rng(42)\n",
    "mask = rng.choice([0, 1], size=len(y), p=[0.9, 0.1])  # 90% 0, 10% 1\n",
    "y = mask\n",
    "\n",
    "# Split estratificat per mantenir la proporció de classes\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Models\n",
    "pipe_svm = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", SVC(kernel=\"rbf\", C=1, random_state=0))\n",
    "])\n",
    "\n",
    "pipe_knn = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", KNeighborsClassifier(n_neighbors=3))\n",
    "])\n",
    "\n",
    "pipe_svm.fit(X_train, y_train)\n",
    "pipe_knn.fit(X_train, y_train)\n",
    "\n",
    "y_predsvm = pipe_svm.predict(X_test)\n",
    "y_predknn = pipe_knn.predict(X_test)\n",
    "\n",
    "# 4. Funció per mostrar mètriques\n",
    "def metrics_dict(y_true, y_pred):\n",
    "    return {\n",
    "        \"Accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"Recall(minoritària)\": recall_score(y_true, y_pred, pos_label=1),\n",
    "        \"F1\": f1_score(y_true, y_pred, pos_label=1),\n",
    "        \"Balanced Accuracy\": balanced_accuracy_score(y_true, y_pred),\n",
    "        \"MCC\": matthews_corrcoef(y_true, y_pred)\n",
    "    }\n",
    "\n",
    "print(\"Mètriques SVM:\\n\", pd.Series(metrics_dict(y_test, y_predsvm)).round(4))\n",
    "print(\"\\nMètriques kNN:\\n\", pd.Series(metrics_dict(y_test, y_predknn)).round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4355542-33dd-483b-86f3-1d10e95ac92d",
   "metadata": {},
   "source": [
    "Tenim les 5 mètriques calculades en els dos models.\n",
    "\n",
    "Si ens fixem en l'accuracy, veiem que ens indica que el SVM és millor, però amb dades desequilibrades, l'accuracy pot indicar que un model va bé tot i no ser el cas. Com en el nostre cas, que tenim una classe majoritària del 90%, el model pot predir sempre la classe negativa i encertar sense fer res.\n",
    "\n",
    "El recall de la classe minoritària ens confirma que l'accuracy és poc fiable, surt molt baix, indicant que els models a penes detecten la classe minoritària.\n",
    "El F1 també ens diu que cap dels dos funciona bé, tot i que en el cas de KNN és una mica millor.\n",
    "\n",
    "Ara, pel que fa al balanced accuracy i el mcc, notem que detecten bé els problemes de desequilibri, en el cas de BA, dona 0.5 en els dos models, indicant que els models no estan classificant res i deixant clar el mal rendiment d'aquests.\n",
    "I el MCC que és la mètrica que millor capta la situació de manera global, ens diu amb aquests números tan baixos que els models de classificació no van bé, i no estan aprenent res útil.\n",
    "\n",
    "D'aquesta manera veiem la paradoxa de l'accuracy, si només ens fixem en aquesta mètrica podem pensar que un model funciona bé quan en realitat, és el contrari, per això, és important mirar altres mètriques més completes com poden ser el BA i el MCC.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cefd7f-81c8-45cd-9144-9c22db7312b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
