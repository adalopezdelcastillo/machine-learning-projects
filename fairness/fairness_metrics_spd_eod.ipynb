{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78138117-f238-441b-b9b9-fa75fe9aea86",
   "metadata": {},
   "source": [
    "Ada López del Castillo Avilés, NIU:1605347"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaa7736-b33c-4da7-9e25-ca7f2e643e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, roc_auc_score, confusion_matrix, roc_curve\n",
    ")\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "# Mesures de puresa (per coherència amb els apunts)\n",
    "def entropy(p):\n",
    "    p = np.asarray(p, dtype=float)\n",
    "    p = p[p > 0]\n",
    "    return -np.sum(p * np.log2(p))\n",
    "\n",
    "def gini(p):\n",
    "    p = np.asarray(p, dtype=float)\n",
    "    return 1.0 - np.sum(p**2)\n",
    "\n",
    "def error_rate(p):\n",
    "    p = np.asarray(p, dtype=float)\n",
    "    return 1.0 - np.max(p)\n",
    "\n",
    "# Mètriques d'equitat (grupal) per atribut sensible A (0=desfavorit, 1=afavorit)\n",
    "# y_true i y_pred són binàries (0/1)\n",
    "\n",
    "def statistical_parity_difference(y_pred, A):\n",
    "    # SPD = |P(ŷ=1|A=1) - P(ŷ=1|A=0)|\n",
    "    p1 = (y_pred[A==1] == 1).mean() if np.any(A==1) else 0.0\n",
    "    p0 = (y_pred[A==0] == 1).mean() if np.any(A==0) else 0.0\n",
    "    return abs(p1 - p0)\n",
    "\n",
    "\n",
    "def statistical_parity_ratio(y_pred, A, eps=1e-12):\n",
    "    # SPR = P(ŷ=1|A=1) / P(ŷ=1|A=0)  (definim 0 si denominador=0 i numerador>0)\n",
    "    p1 = (y_pred[A==1] == 1).mean() if np.any(A==1) else 0.0\n",
    "    p0 = (y_pred[A==0] == 1).mean() if np.any(A==0) else 0.0\n",
    "    if p0 < eps and p1 < eps:\n",
    "        return 1.0  # ambdues 0 → paritat trivial\n",
    "    if p0 < eps:\n",
    "        return 0.0\n",
    "    return p1 / p0\n",
    "\n",
    "\n",
    "def equal_opportunity_difference(y_true, y_pred, A):\n",
    "    # EOD = |TPR(A=1) - TPR(A=0)|, on TPR = P(ŷ=1|Y=1, A)\n",
    "    mask1 = (y_true==1) & (A==1)\n",
    "    mask0 = (y_true==1) & (A==0)\n",
    "    tpr1 = (y_pred[mask1] == 1).mean() if np.any(mask1) else 0.0\n",
    "    tpr0 = (y_pred[mask0] == 1).mean() if np.any(mask0) else 0.0\n",
    "    return abs(tpr1 - tpr0)\n",
    "\n",
    "\n",
    "def predictive_equality_difference(y_true, y_pred, A):\n",
    "    # PED = |FPR(A=1) - FPR(A=0)|, FPR = P(ŷ=1|Y=0, A)\n",
    "    mask1 = (y_true==0) & (A==1)\n",
    "    mask0 = (y_true==0) & (A==0)\n",
    "    fpr1 = (y_pred[mask1] == 1).mean() if np.any(mask1) else 0.0\n",
    "    fpr0 = (y_pred[mask0] == 1).mean() if np.any(mask0) else 0.0\n",
    "    return abs(fpr1 - fpr0)\n",
    "\n",
    "\n",
    "def group_confusions(y_true, y_pred, A):\n",
    "    # Taules de confusió per grup\n",
    "    return {\n",
    "        g: confusion_matrix(y_true[A==g], y_pred[A==g], labels=[0,1]) if np.any(A==g) else np.zeros((2,2), dtype=int)\n",
    "        for g in [0,1]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15228fad-16c2-40ee-95d0-176261d45333",
   "metadata": {},
   "source": [
    "## Exercici 1: Càlcul manual de mètriques d'equitat\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba554a7-4af3-4d5f-89ad-1afc7f029acd",
   "metadata": {},
   "source": [
    "Considera la taula següent (construïda sobre el conjunt test d'un model):\n",
    "- Grup A=0 (desfavorit): TP=40, FP=20, TN=110, FN=30\n",
    "- Grup A=1 (afavorit): TP=55, FP=15, TN=115, FN=15\n",
    "\n",
    "Calcula TPR i FPR per a cada grup. \n",
    "Calcula EOD i PED. \n",
    "Si el model donava (P(\\hat{Y}=1|A=0)=\\frac{TP+FP}{N_0}) i (P(\\hat{Y}=1|A=1)=\\frac{TP+FP}{N_1}), calcula SPD i SPR.\n",
    "\n",
    "Pista: (N_g = TP+FP+TN+FN) per cada grup. Definicions segons Tema 7 de teoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59527ca9-7cdd-45ce-a7cf-85edf270a33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Posem les dades del grup 0 i 1, i després les classifiquem en predictives i observades\n",
    "\n",
    "TP0, FP0, TN0, FN0 = 40, 20, 110, 30 \n",
    "TP1, FP1, TN1, FN1 = 55, 15, 115, 15  \n",
    "\n",
    "A_0 = np.zeros(TP0 + FP0 + TN0 + FN0, dtype=int)\n",
    "y_true_0 = np.array([1]*(TP0+FN0) + [0]*(FP0+TN0), dtype=int)\n",
    "y_pred_0 = np.array([1]*TP0 + [0]*FN0 + [1]*FP0 + [0]*TN0, dtype=int)\n",
    "\n",
    "A_1 = np.ones(TP1 + FP1 + TN1 + FN1, dtype=int)\n",
    "y_true_1 = np.array([1]*(TP1+FN1) + [0]*(FP1+TN1), dtype=int)\n",
    "y_pred_1 = np.array([1]*TP1 + [0]*FN1 + [1]*FP1 + [0]*TN1, dtype=int)\n",
    "\n",
    "#Ajuntem els dos grups, la informació (seria com construir la matriu confusió manualment)\n",
    "A = np.concatenate([A_0, A_1])\n",
    "y_true = np.concatenate([y_true_0, y_true_1])\n",
    "y_pred = np.concatenate([y_pred_0, y_pred_1])\n",
    "\n",
    "#Calcul de TPR i FPR de cada grup\n",
    "def tpr_fpr(y_true, y_pred, A, g):\n",
    "    # TPR = P(ŷ=1 | Y=1, A=g)\n",
    "    mask_pos = (y_true == 1) & (A == g)\n",
    "    tpr = (y_pred[mask_pos] == 1).mean() if np.any(mask_pos) else 0.0\n",
    "\n",
    "    # FPR = P(ŷ=1 | Y=0, A=g)\n",
    "    mask_neg = (y_true == 0) & (A == g)\n",
    "    fpr = (y_pred[mask_neg] == 1).mean() if np.any(mask_neg) else 0.0\n",
    "    return tpr, fpr\n",
    "\n",
    "#Guardem els resultats i els imprimim\n",
    "TPR0, FPR0 = tpr_fpr(y_true, y_pred, A, g=0)\n",
    "TPR1, FPR1 = tpr_fpr(y_true, y_pred, A, g=1)\n",
    "\n",
    "print(\"TPR0 =\", TPR0, \"i FPR0 =\", FPR0)\n",
    "print(\"TPR1 =\", TPR1, \"i FPR1 =\", FPR1)\n",
    "\n",
    "#Ara calculem EOD i PED i els imprimim\n",
    "EOD = equal_opportunity_difference(y_true, y_pred, A)\n",
    "PED = predictive_equality_difference(y_true, y_pred, A)\n",
    "\n",
    "print(\"\\nEOD =\", EOD)\n",
    "print(\"PED =\", PED)\n",
    "\n",
    "# Per últim calculem SPD i SPR\n",
    "SPD = statistical_parity_difference(y_pred, A)\n",
    "SPR = statistical_parity_ratio(y_pred, A)\n",
    "\n",
    "print(\"\\nSPD =\", SPD)\n",
    "print(\"SPR =\", SPR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4961ee5-3362-4184-8099-fa83f15c31b3",
   "metadata": {},
   "source": [
    "Primer s'han construit les matrius de confusió de cada grup i s'ha calculat TPR i FPR de cadascun.\n",
    "Amb aquestes dades s'han calculat les mètriques d'equitat, EOD=0.214 que és una diferència important i indica que el model està predint més falsos negatius en el cas del grup A=0, per tant no detecta bé els positius reals.\n",
    "\n",
    "En el cas del PED=0.038 surt un valor molt més petit, el qual indica que el model està patint falsos positius de manera similar en els dos grups, tot i que el A=1 segueix tenint una taxa lleugerament millor.\n",
    "\n",
    "A més s'ha calculat el SPD i el SPR que indiquen que el model assigna més prediccions positives al grup A=1, per tant podem concloure que el model afavoreix al grup A=1.\n",
    "\n",
    "Per tant, el problema està en els falsos negatius del grup A=0, que és on realment hi ha una diferència important comparat amb el grup A=1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1e8ee0-ad8c-49ff-b96e-8dd367aedc04",
   "metadata": {},
   "source": [
    "### Exercici 2: Tuning de k al k-NN i compromís equitat–rendiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e25a934-3ea2-46ec-abb1-59040fbf3055",
   "metadata": {},
   "source": [
    "Usant el dataset sintètic:\n",
    "\n",
    "- Avalua k-NN per k ∈ {1,3,5,7,11,15,21} amb 5-fold CV (estratificada).\n",
    "- Dibuixa ACC i SPD/EOD en funció de k.\n",
    "- Escull k sota el criteri: minimitzar SPD subjecte a ACC ≥ (ACC màxim − 0.02).\n",
    "\n",
    "Pista: Recorda estandarditzar features per a k-NN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516d1da5-921d-4f1d-9bc1-4e823e4ed70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import expit\n",
    "\n",
    "n = 5000\n",
    "A = np.random.binomial(1, 0.5, size=n)\n",
    "X1 = np.random.normal(0.5*A, 1.0, size=n)\n",
    "X2 = np.random.normal(0.3*A, 1.0, size=n)  # segon predictor correlacionat\n",
    "X = np.c_[X1, X2]\n",
    "\n",
    "# Probabilitat positiva amb model logístic (beta0=0, beta=[1,1])\n",
    "logit = 0.0 + 1.0*X1 + 1.0*X2\n",
    "p = expit(logit)\n",
    "Y = np.random.binomial(1, p)\n",
    "\n",
    "synth = pd.DataFrame({\"X1\":X1, \"X2\":X2, \"A\":A, \"Y\":Y})\n",
    "synth.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a94f2c-0082-43e1-b698-616265c0addd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fem una funció que avalui Knn pels diferents valors donats i que calculi ACC; EOD; SPD\n",
    "k_valors= [1, 3, 5, 7, 11, 15, 21]\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "rows = []\n",
    "\n",
    "for k in k_valors:\n",
    "    acc_folds = []\n",
    "    spd_folds = []\n",
    "    eod_folds = []\n",
    "\n",
    "    model = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"knn\", KNeighborsClassifier(n_neighbors=k))\n",
    "    ])\n",
    "\n",
    "    for train_idx, test_idx in cv.split(X, Y):\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = Y[train_idx], Y[test_idx]\n",
    "        A_test = A[test_idx]\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        spd = statistical_parity_difference(y_pred, A_test)\n",
    "        eod = equal_opportunity_difference(y_test, y_pred, A_test)\n",
    "\n",
    "        acc_folds.append(acc)\n",
    "        spd_folds.append(spd)\n",
    "        eod_folds.append(eod)\n",
    "\n",
    "    rows.append({\n",
    "        \"k\": k,\n",
    "        \"ACC\": np.mean(acc_folds),\n",
    "        \"SPD\": np.mean(spd_folds),\n",
    "        \"EOD\": np.mean(eod_folds),\n",
    "    })\n",
    "\n",
    "resultats = pd.DataFrame(rows).sort_values(\"k\")\n",
    "print(resultats)\n",
    "\n",
    "#Representem els valors en funció de k en un gràfic\n",
    "plt.plot(resultats[\"k\"], resultats[\"ACC\"], marker=\"o\")\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"Accuracy (mitjana CV)\")\n",
    "plt.title(\"ACC vs k (k-NN, 5-fold CV)\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(resultats[\"k\"], resultats[\"SPD\"], marker=\"o\", label=\"SPD\")\n",
    "plt.plot(resultats[\"k\"], resultats[\"EOD\"], marker=\"o\", label=\"EOD\")\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"Mètrica d'equitat (mitjana CV)\")\n",
    "plt.title(\"Equitat vs k (k-NN, 5-fold CV)\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e39ed4-d72f-4f5b-be52-9f15cc1c2031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACC màxima\n",
    "acc_max = resultats[\"ACC\"].max()\n",
    "\n",
    "# Restricció: ACC ≥ ACC_max − 0.02\n",
    "candidats = resultats[resultats[\"ACC\"] >= acc_max - 0.02]\n",
    "\n",
    "# Minimitzem SPD sota la restricció donada\n",
    "k_opt = candidats.sort_values(\"SPD\").iloc[0][\"k\"]\n",
    "\n",
    "#Imprimim el valor de la ACC màxima, els candidats i finalment k escollit\n",
    "print(\"ACC màxima:\", acc_max)\n",
    "print(\"Candidats:\")\n",
    "print(candidats)\n",
    "print(\"k seleccionat:\", k_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bfbd1d-8a36-4701-b84b-2793c1d94759",
   "metadata": {},
   "source": [
    "S'ha avaluat el model KNN amb els diferents valors donats amb CV 5 i s'han estandaritzat les dades tal i com es demanava, després s'ha mesurat ACC, SPD i EOD amb cadascuna d'elles i s'ha imprés per pantalla, després s'ha dibuixat per a una millor comprensió.\n",
    "A la gràfica, s'observa que l'accuracy va augmentant a mesura que k creix, això és degut a que en el model Knn normalment amb k petit el model és més sorollós i poc estable i a mesura que anem augmentant la k, es va estabilitzant i millorant el rendiment.\n",
    "Ara, la gràfica de EOD i SPD veiem que el SPD va empitjoran a mesura que la k augmenta (SPD augmenta també), això indica que en pujar la k, el percentatge de prediccions positives es separa més entre grups. I pel que fa al EOD, també creix a mesura que augmenta la k.\n",
    "\n",
    "Amb tota aquesta informació, s'ha usat un criteri en concret: minimitzar SPD subecte a ACC>= ACC max -0.02 per tal d'escollir la millor k per aquest dataset, i ens ha sortit k=7, és a dir, un valor entre mig de tots, això té sentit perquè hem vist que al pujar la k, millorem el rendiment pero perdem equitat (augmenta SPD), es per això que el valor k=7 ha sortit el millor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462ad7b5-c6f4-43dd-af99-063b577e7d4e",
   "metadata": {},
   "source": [
    "### Exercici 3: Profunditat de l'arbre i equitat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1619ca99-34cf-4e6a-a8df-6c86b4f1da22",
   "metadata": {},
   "source": [
    "Avaluarem DecisionTreeClassifier amb max_depth ∈ {1..10} sobre el dataset sintètic.\n",
    "\n",
    "- Representa ACC i SPD en funció de la profunditat.\n",
    "- Identifica el punt on l'increment de profunditat no millora ACC però empitjora l'equitat (increment de SPD)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e233eb85-4dd6-4e36-bf3e-3ccecce1a62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fem el mateix que en l'anterior exercici però calculant ACC I SPD en DecisionTree\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "depths = range(1, 11)\n",
    "rows = []\n",
    "\n",
    "for d in depths:\n",
    "    accs, spds = [], []\n",
    "    clf = DecisionTreeClassifier(max_depth=d, criterion=\"gini\", random_state=42)\n",
    "\n",
    "    for tr, te in cv.split(X, Y):\n",
    "        clf.fit(X[tr], Y[tr])\n",
    "        yhat = clf.predict(X[te])\n",
    "\n",
    "        accs.append(accuracy_score(Y[te], yhat))\n",
    "        spds.append(statistical_parity_difference(yhat, A[te]))  # <-- IMPORTANT\n",
    "\n",
    "    rows.append([d, np.mean(accs), np.mean(spds)])\n",
    "\n",
    "resultats = pd.DataFrame(rows, columns=[\"depth\", \"ACC\", \"SPD\"])\n",
    "\n",
    "#\n",
    "plt.figure()\n",
    "plt.plot(resultats.depth, resultats.ACC, marker='o')\n",
    "plt.xlabel(\"max_depth\")\n",
    "plt.ylabel(\"Accuracy (mitjana CV)\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(resultats.depth, resultats.SPD, marker='o')\n",
    "plt.xlabel(\"max_depth\")\n",
    "plt.ylabel(\"SPD (mitjana CV)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dda7ea2-89b8-41f3-b59b-c9b861a9249a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diferències entre profunditats consecutives\n",
    "resultats[\"ACC_diff\"] = resultats[\"ACC\"].diff()\n",
    "resultats[\"SPD_diff\"] = resultats[\"SPD\"].diff()\n",
    "\n",
    "# Punt on augmentar profunditat ja no millora ACC però empitjora equitat (SPD)\n",
    "tol = 0.001\n",
    "problematic = resultats[(resultats[\"ACC_diff\"] <= tol) & (resultats[\"SPD_diff\"] > 0)]\n",
    "\n",
    "print(resultats.round(4))\n",
    "print(\"\\nPunts problemàtics (ACC no millora > tol i SPD empitjora):\")\n",
    "print(problematic.round(4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eaec15e-18de-49d1-ad85-dc29fa840d60",
   "metadata": {},
   "source": [
    "S'ha avaluat un DecisionTree canviant la profunditat a diversos valors sobre el mateix dataset que l'anterior exercici, i s'ha mesurat l'accuracy i el SPD en cadascuna de les profunditats.\n",
    "El que s'ha observat és que el rendiment millorava al usar profunditats més elevades (del 1 al 4 hi ha una millora de rendiment), però passada una profunditat (la 4), el rendiment torna a decaure de manera molt lleugera, això pot ser degut a un overfitting i pèrdua de generalització.\n",
    "Pel que fa a la SPD els valors van canviant sense un patró clar, però si que és veu q en aporfunidir més, l'equitat empitjora.\n",
    "\n",
    "Després s'ha impres per pantalla els resultats numèrics de totes les profunditats i s'ha escollit el punt on en augmentar la profunditat no millora l'ACC i augmenta SPD, i ha del 4 al 5, fent així que sigui el punt on convé aturar-se.\n",
    "Per tant fer un arbre més complex no garanteix que sigui millor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e54dda-edd7-4fc2-adb5-1855cbc979f0",
   "metadata": {},
   "source": [
    "### Exercici 4: Probabilitats amb SVM (Platt) i efecte en l'equitat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c11d596-ab3e-40d1-99b5-dfc56ca243df",
   "metadata": {},
   "source": [
    "1. Ajusta una SVM lineal al dataset sintètic i obtén probabilitats calibrades (probability=True aplica una aproximació tipus Platt scaling).\n",
    "2. Compara mètriques d'equitat i AUC amb i sense calibració (aprox. usar SVC(..., probability=True) vs decision_function (sigmoide manual)).\n",
    "3. Discutiu: millorar la calibració del score ajuda a fixar llindars que milloren el compromís equitat–rendiment?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15c8b14-e73c-45e9-9b8d-c93caebcfa43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fem una SVM lineal\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "vals = []\n",
    "\n",
    "for tr, te in cv.split(X, Y):\n",
    "    Xtr, Xte = X[tr], X[te]\n",
    "    ytr, yte = Y[tr], Y[te]\n",
    "    Ate = A[te]\n",
    "\n",
    "    #Estandaritzem les dades com sempre\n",
    "    sc = StandardScaler()\n",
    "    Xtr_s = sc.fit_transform(Xtr)\n",
    "    Xte_s = sc.transform(Xte)\n",
    "\n",
    "    #SVM calibrada\n",
    "    svm_calibrada = SVC(kernel=\"linear\", probability=True, random_state=42)\n",
    "    svm_calibrada.fit(Xtr_s, ytr)\n",
    "    p_cal = svm_calibrada.predict_proba(Xte_s)[:, 1]\n",
    "    yhat_cal = (p_cal >= 0.5).astype(int)\n",
    "\n",
    "    #SVM no calibrada\n",
    "    svm_no_cal = SVC(kernel=\"linear\", probability=False, random_state=42)\n",
    "    svm_no_cal.fit(Xtr_s, ytr)\n",
    "    score = svm_no_cal.decision_function(Xte_s)\n",
    "    #sigmoide\n",
    "    p_no_cal = expit(score)          \n",
    "    yhat_no_cal = (p_no_cal >= 0.5).astype(int)\n",
    "\n",
    "    vals.append([\n",
    "        accuracy_score(yte, yhat_cal),\n",
    "        roc_auc_score(yte, p_cal),\n",
    "        statistical_parity_difference(yhat_cal, Ate),\n",
    "        equal_opportunity_difference(yte, yhat_cal, Ate),\n",
    "        predictive_equality_difference(yte, yhat_cal, Ate),\n",
    "\n",
    "        accuracy_score(yte, yhat_no_cal),\n",
    "        roc_auc_score(yte, score),  \n",
    "        statistical_parity_difference(yhat_no_cal, Ate),\n",
    "        equal_opportunity_difference(yte, yhat_no_cal, Ate),\n",
    "        predictive_equality_difference(yte, yhat_no_cal, Ate),\n",
    "    ])\n",
    "\n",
    "res = pd.DataFrame(vals, columns=[\n",
    "    \"ACC_cal\",\"AUC_cal\",\"SPD_cal\",\"EOD_cal\",\"PED_cal\",\n",
    "    \"ACC_no_cal\",\"AUC_no_cal\",\"SPD_no_cal\",\"EOD_no_cal\",\"PED_no_cal\"\n",
    "])\n",
    "\n",
    "summary = pd.DataFrame({\n",
    "    \"metrica\": [\"ACC\",\"AUC\",\"SPD\",\"EOD\",\"PED\"],\n",
    "    \"SVM_calibrada\": [\n",
    "        res[\"ACC_cal\"].mean(), res[\"AUC_cal\"].mean(),\n",
    "        res[\"SPD_cal\"].mean(), res[\"EOD_cal\"].mean(), res[\"PED_cal\"].mean()\n",
    "    ],\n",
    "    \"SVM_no_cal\": [\n",
    "        res[\"ACC_no_cal\"].mean(), res[\"AUC_no_cal\"].mean(),\n",
    "        res[\"SPD_no_cal\"].mean(), res[\"EOD_no_cal\"].mean(), res[\"PED_no_cal\"].mean()\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(summary.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ca0ade-0763-4609-8af8-fbd026c52cb7",
   "metadata": {},
   "source": [
    "S'ha entrenat una SVM lineal sobre el dataset sintètic i s'han comparat dues maneres d'obtenir probabilitats, la calibrada i la no calibrada. I s'han comparat ACC, AUC, les mètriques de equitat SPD, EOD, PED amb un llindar de 0.5.\n",
    "Notem que l'accuracy canvia molt poc, hi ha el mateix rendiment, i AUC és exactament igual.\n",
    "Ara, en quant a les de equitat si que hi ha una mica més de canvi, la no calibrada dona millors valors en les 3 mètriques (però la diferència és molt petita).\n",
    "\n",
    "Per tant, tot i que la calibració no ajuda a millorar l'equitat amb aquest llindar, calibrar és útil ja que els resultats són més interpretables. En aquest cas no calia calibrar, però la calibració és interessant si volem ajustar el llindar de decisió de manera controlada per optimitzar el compromís equitat–rendiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d906f351-eaf7-4922-a479-93108466afb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
