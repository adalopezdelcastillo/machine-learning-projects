{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a9488eb-2499-456c-995b-f444cc14ac2d",
   "metadata": {},
   "source": [
    "Ada López del Castillo Avilés, NIU:1605347"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3f7486-7f1d-4d89-bdbf-80ed1367c571",
   "metadata": {},
   "source": [
    "### Exercici 1: Càlcul manual de Gini, entropia i error rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554b8eb9-675b-4a3b-a134-4a700387f465",
   "metadata": {},
   "source": [
    "Considera el següent node d'un arbre de classificació binària:\n",
    "\n",
    "A la regió hi ha 20 observacions (15 classe 1 (positiva) i 5 de classe 0 (negativa)).\n",
    "- Calcula les probabilitats empíriques de cada classe al node.\n",
    "- Calcula l'error rate del node.\n",
    "- Calcula l'índex de Gini del node.\n",
    "- Calcula l'entropia (en bits, base 2) del node.\n",
    "Interpreta els valors obtinguts: el node és molt pur, una mica impur...?\n",
    "Després, suposa que fem un split d'aquest node en dos fills amb les següents distribucions:\n",
    "\n",
    "Fill esquerre: 8 positius, 2 negatius (10 observacions en total).\n",
    "Fill dret: 7 positius, 3 negatius (10 observacions en total).\n",
    "- Calcula les probabilitats, Gini, entropia i error rate de cadascun dels fills.\n",
    "- Calcula la impuresa ponderada (pel Gini i per l'entropia) del split.\n",
    "- Compara la impuresa abans i després del split: ha millorat la puresa? En quin sentit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f63814-bdc9-49dc-a939-e3bba702af1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, confusion_matrix, classification_report,\n",
    "    ConfusionMatrixDisplay\n",
    ")\n",
    "\n",
    "# Perquè les figures surtin dins del notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# Fixem llavor per a la reproductibilitat\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "def entropy(p):\n",
    "    \"\"\"Entropia de Shannon per a un vector de probabilitats p (base 2).\"\"\"\n",
    "    p = np.asarray(p, dtype=float)\n",
    "    p = p[p > 0]  # eliminem probabilitats 0 per evitar log(0)\n",
    "    return -np.sum(p * np.log2(p))\n",
    "\n",
    "def gini(p):\n",
    "    \"\"\"Índex de Gini per a un vector de probabilitats p.\"\"\"\n",
    "    p = np.asarray(p, dtype=float)\n",
    "    return 1.0 - np.sum(p**2)\n",
    "\n",
    "def error_rate(p):\n",
    "    \"\"\"Error rate = 1 - max_k p_k.\"\"\"\n",
    "    p = np.asarray(p, dtype=float)\n",
    "    return 1.0 - np.max(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccbdd1b-2731-40c7-a4a3-bf0de71610ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construïm el dataset amb les 20 observacions\n",
    "data_ex1 = pd.DataFrame({\n",
    "    \"Y\":  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]\n",
    "})\n",
    "\n",
    "data_ex1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb0a6ae-0fbb-41c3-adf3-81e1941f9f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mirem quants hi ha de cada classe\n",
    "counts_root = data_ex1['Y'].value_counts().sort_index()\n",
    "counts_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0044c3b2-6f0a-4e1e-a09e-b2a57aacb0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probabilitats empíriques de cada classe al node arrel\n",
    "p_root = counts_root / counts_root.sum()\n",
    "\n",
    "# Calculem les probabilitats empíriques, l'error rate, l'índex de Gini i l'entropia del node\n",
    "print(\"Probabilitats al node arrel:\", p_root.to_dict())\n",
    "print(\"Error rate:\", error_rate(p_root))\n",
    "print(\"Gini:\", gini(p_root))\n",
    "print(\"Entropia (bits):\", entropy(p_root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22884e5e-bec0-4748-9ec8-b7d1906cf8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ara fem un split d'aquest node en dos fills:\n",
    "\n",
    "p_left  = np.array([2/10, 8/10])   # fill esquerre\n",
    "p_right = np.array([3/10, 7/10])   # fill dret\n",
    "\n",
    "print(\"Fill esquerre (8 positius, 2 negatius)\")\n",
    "print(\"Probabilitats:\", p_left)\n",
    "print(\"Error rate:\", error_rate(p_left))\n",
    "print(\"Gini:\", gini(p_left))\n",
    "print(\"Entropia:\", entropy(p_left))\n",
    "print()\n",
    "\n",
    "print(\"Fill dret (7 positius, 3 negatius)\")\n",
    "print(\"Probabilitats:\", p_right)\n",
    "print(\"Error rate:\", error_rate(p_right))\n",
    "print(\"Gini:\", gini(p_right))\n",
    "print(\"Entropia:\", entropy(p_right))\n",
    "print()\n",
    "\n",
    "#Impuresa ponderada del split\n",
    "w_left = 10/20\n",
    "w_right = 10/20\n",
    "\n",
    "Gini_split = w_left * gini(p_left) + w_right * gini(p_right)\n",
    "Entropia_split = w_left * entropy(p_left) + w_right * entropy(p_right)\n",
    "print(\"Gini amb impuresa ponderada:\", Gini_split)\n",
    "print(\"Entropia amb impuresa ponderada:\", Entropia_split)\n",
    "print()\n",
    "\n",
    "#Imprimim les dades abans i després del split\n",
    "print(\"Gini abans del split:\", gini(p_root))\n",
    "print(\"Gini després del split:\", Gini_split)\n",
    "print(\"Entropia abans del split:\", entropy(p_root))\n",
    "print(\"Entropia després del split:\", Entropia_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1395ff5-f466-4732-8c15-fdb696c00d9f",
   "metadata": {},
   "source": [
    "S'ha construït un dataframe amb 20 observacions, 15 de classe 1 i 5 de classe 0 (positiva i negativa respectivament), per això les probabilitats empíriques són p(1)=0.75 i p(0)= 0.25.\n",
    "Després s'ha calculat l'error rate i n'ha sortit 0.25, indicant que la regla de classificació que assigna sempre la classe majoritària (la positiva) s'equivocaria en un 25% dels casos.\n",
    "\n",
    "L'índex de Gini val 0.375 i l'entropia 0.81 bits indicant que el node no és pur (pur seria valors 0), però donat que hi ha una classe clarament dominant, la impuresa no és màxima.  \n",
    "\n",
    "Ara, després de fer el split notem que els valors de Gini i entropia disminueixen molt lleugerament, això vol dir que disminueix la impuresa, ja que a menys valor, més pur, però d'una manera molt lleugera, per tant, els nodes fills són una mica més purs que el node original."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8baaa8c7-dd77-41c4-8065-3d3d3499dae0",
   "metadata": {},
   "source": [
    "### Exercici 2: Dades simulades 2D i sobreajustament (overfitting)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b7633f-016d-45a5-992e-434a14587348",
   "metadata": {},
   "source": [
    "Genera un conjunt de dades 2D de classificació binària amb la funció make_blobs de sklearn.datasets, amb:\n",
    "- 2 features (coordenades en 2D).\n",
    "- 2 centres ben separats.\n",
    "- 500 observacions.\n",
    "  \n",
    "Fes un train/test split amb test_size=0.3 i random_state=RANDOM_STATE.\n",
    "\n",
    "Entrena dos arbres de decisió:\n",
    "- Arbre A: max_depth=None (sense límit, arbre molt profund).\n",
    "- Arbre B: max_depth=3.\n",
    "\n",
    "Calcula l'accuracy de cadascun dels models en train i en test.\n",
    "\n",
    "Representa aproximadament les fronteres de decisió en 2D per als dos models en dues figures separades.\n",
    "\n",
    "Compara els resultats: hi ha senyals de sobreajustament a l'arbre A? Explica el que observes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257a25c8-0bdd-4eb9-97c3-9d26f1e20f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "# Conjunt de dades 2D amb 2 centres molt separats i 500 observacions\n",
    "X, y = make_blobs(\n",
    "    n_samples=500,\n",
    "    centers=[(-3, -3), (3, 3)],   # separem els centres\n",
    "    n_features=2,\n",
    "    cluster_std=2,                # Deixem així per tal de que no surti tot amb precisió 1     \n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "#Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "#Fem els dos arbres de decisió:\n",
    "tree_A = DecisionTreeClassifier(\n",
    "    criterion=\"gini\",\n",
    "    max_depth=None,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "tree_A.fit(X_train, y_train)\n",
    "\n",
    "tree_B = DecisionTreeClassifier(\n",
    "    criterion=\"gini\",\n",
    "    max_depth=3,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "tree_B.fit(X_train, y_train)\n",
    "\n",
    "#Imprimim els resultats del accuracy en train i test\n",
    "print(\"Arbre A\")\n",
    "print(\"Train accuracy:\", tree_A.score(X_train, y_train))\n",
    "print(\"Test accuracy :\", tree_A.score(X_test, y_test))\n",
    "\n",
    "print(\"\\nArbre B\")\n",
    "print(\"Train accuracy:\", tree_B.score(X_train, y_train))\n",
    "print(\"Test accuracy :\", tree_B.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564d8b6e-fb05-471b-98bd-9ed601c1b50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Fem les figures que representin les fronteres de decisió dels dos models usant la funció DecisionBoundaryDisplay\n",
    "plt.figure(figsize=(6, 5))\n",
    "DecisionBoundaryDisplay.from_estimator(\n",
    "    tree_A,\n",
    "    X_train,\n",
    "    response_method=\"predict\",\n",
    "    cmap=\"bwr\",\n",
    "    alpha=0.3\n",
    ")\n",
    "plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=\"bwr\", edgecolor=\"k\")\n",
    "plt.title(\"Frontera de decisió de l'Arbre A \")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "DecisionBoundaryDisplay.from_estimator(\n",
    "    tree_B,\n",
    "    X_train,\n",
    "    response_method=\"predict\",\n",
    "    cmap=\"bwr\",\n",
    "    alpha=0.3\n",
    ")\n",
    "plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=\"bwr\", edgecolor=\"k\")\n",
    "plt.title(\"Frontera de decisió de l'Arbre B\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8931ee1-a161-4299-b236-105080417f37",
   "metadata": {},
   "source": [
    "En aquest exercici es demanava generar un conjunt de dades 2D de classificació binària, fer un train/test split i entrenar dos arbres de decisió amb profunditats diferents, després s'ha calculat l'accuracy.\n",
    "\n",
    "Notem que per fer els centres ben separats (i així tenir els grups separats), en comptes de posar un valor molt baix en el cluster_std, s'han separat imposant que un estigui (-3,-3) i l'altre (3,3), i s'ha deixat el cluster_std en 2 per tal de tenir dades interessants.\n",
    "\n",
    "Tot i així, han sortit accuracys molt semblants, en el cas de l'arbre A, el train accuracy ha estat d'1 i el test accuracy de 0.94, pel que sabem que és capaç de classificar perfectament totes les observacions del conjunt d'entrenament, i que té un rendiment una mica pitjor en el cas del conjunt test.\n",
    "\n",
    "En la seva representació, veiem que hi ha diversos talls verticals i horitzontals que s'adapten als punts d'entrenament, per tant, la frontera és complexa.\n",
    "\n",
    "L'arbre B, que tenia la profunditat limitada, ha obtingut un train accuracy una mica pitjor (tot i ser molt elevat també) de 0.98, però un test accuracy superior al de l'A i respecte a la seva representació, la frontera de decisió és molt més simple.\n",
    "\n",
    "Llavors podem concloure que limitar la profunditat millora la generalització del model, i que en el cas de l'arbre A hi ha hagut overfitting, és per això que l'arbre B ha aconseguit un millor equilibri de rendiment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce84bda-78b8-402c-9280-1a0b452dd697",
   "metadata": {},
   "source": [
    "### Exercici 3: Profunditat òptima en el dataset de breast cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b802309-8472-4b87-a12f-cd199577d96c",
   "metadata": {},
   "source": [
    "1. Fes un train/test split del dataset de breast cancer (si no el tens, torna'l a carregar).\n",
    "2. Per a valors de max_depth entre 1 i 10, entrena un DecisionTreeClassifier (criteri Gini, random_state=RANDOM_STATE).\n",
    "3. Per a cada valor de max_depth, calcula l'accuracy en train i en test.\n",
    "4. Representa en una mateixa figura l'accuracy train i test en funció de max_depth.\n",
    "5. Tria una profunditat \"òptima\" segons el comportament de les corbes.\n",
    "6. Entrena de nou un arbre amb aquesta profunditat òptima i mostra la confusion_matrix i l'accuracy en test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0096c236-3415-4799-a37f-4d2ad1f4d8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "#Carreguem el dataset i fem un train/test split\n",
    "cancer = load_breast_cancer(as_frame=True)\n",
    "X_cancer = cancer.data\n",
    "y_cancer = cancer.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_cancer, y_cancer,\n",
    "    test_size=0.3,\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=y_cancer\n",
    ")\n",
    "\n",
    "X_train.shape, X_test.shape\n",
    "\n",
    "#Fem un bucle que entreni un DecisionTreeClassifier amb valors del max_depth del 1 al 10\n",
    "max_depth_valors = range(1, 11)\n",
    "\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "for d in max_depth_valors:\n",
    "    tree = DecisionTreeClassifier(\n",
    "        criterion=\"gini\",\n",
    "        max_depth=d,\n",
    "        random_state=RANDOM_STATE\n",
    "    )\n",
    "    tree.fit(X_train, y_train)\n",
    "    \n",
    "    train_acc = tree.score(X_train, y_train)\n",
    "    test_acc  = tree.score(X_test, y_test)\n",
    "\n",
    "    train_accuracies.append(train_acc)\n",
    "    test_accuracies.append(test_acc)\n",
    "\n",
    "    #L'accuracy de cada valor:\n",
    "    print(f\"Depth {d}: train={train_acc:.4f}, test={test_acc:.4f}\")\n",
    "\n",
    "#Representem graficament l'accuracy train i test en funció dels max_depth\n",
    "plt.figure(figsize=(7, 4))\n",
    "plt.plot(max_depth_valors, train_accuracies, marker=\"o\", label=\"Train accuracy\")\n",
    "plt.plot(max_depth_valors, test_accuracies, marker=\"o\", label=\"Test accuracy\")\n",
    "plt.xlabel(\"max_depth\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Accuracy en train i test segons max_depth\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddeaed8-23b6-495e-bed1-b9603b8a9e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Busquem quin és el millor valor per trobar la profunditat òptima i el guardem\n",
    "idx_best = int(np.argmax(test_accuracies))\n",
    "prof_optima = list(max_depth_valors)[idx_best]\n",
    "\n",
    "# Imprimim el resultat trobat i els seus accuracies corresponents\n",
    "print(\"Profunditat òptima segons test accuracy:\", prof_optima)\n",
    "print(\"Train accuracy a la prof. òptima:\", train_accuracies[idx_best])\n",
    "print(\"Test accuracy a la prof. òptima :\", test_accuracies[idx_best])\n",
    "\n",
    "\n",
    "# Entrenem l'arbre definitiu amb la profunditat òptima\n",
    "tree_cancer_opt = DecisionTreeClassifier(\n",
    "    criterion=\"gini\",\n",
    "    max_depth=prof_optima,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "tree_cancer_opt.fit(X_train, y_train)\n",
    "\n",
    "#Prediccions i accuracy al test\n",
    "y_pred_opt = tree_cancer_opt.predict(X_test)\n",
    "acc_opt = accuracy_score(y_test, y_pred_opt)\n",
    "\n",
    "#Matriu de confusió\n",
    "cm_optima = confusion_matrix(y_test, y_pred_opt)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_optima, display_labels=cancer.target_names)\n",
    "disp.plot(cmap=\"Blues\")\n",
    "plt.title(f\"Breast cancer – Matriu de confusió (max_depth={prof_optima})\")\n",
    "plt.show()\n",
    "\n",
    "# Informe de classificació\n",
    "print(\"Classification report (test):\")\n",
    "print(classification_report(y_test, y_pred_opt, target_names=cancer.target_names))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0164c198-323d-4673-8efa-726756ab0424",
   "metadata": {},
   "source": [
    "S'ha fet un model d'entrenament del dataset Cancer Breast per estudiar la relació entre la profunditat màxima de l’arbre de decisió (max_depth) i la capacitat de generalització del model, és per això que s'ha fet un bucle que entreni un DecisionTree amb diferents profunditats amb criteri Gini, i s'ha calculat l'accuracy amb cadascun dels valors tant en train com en test, a la gràfica es pot veure els diferents valors dels dos tipus de dades.\n",
    "\n",
    "Notem com l'accuracy en train augmenta al màxim a partir del max_depth 6, indicant que l'arbre memoritza les dades d'entrenament a la perfecció, però, en canvi, en l'accuracy del test creix al principi fins a obtenir el màxim al max_depth 5 i després disminueix lleugerament i es manté al 0.918, això pot ser per un overfitting, el model ha memoritzat tant el conjunt train que no sap generalitzar, i per això empitjora en augmentar profunditat.\n",
    "\n",
    "Després, s'ha trobat la profunditat òptima, la qual ha estat amb max_depth 5, que és la que té major accuraccy test i s'ha fet el seu model d'entrenament i una matriu de confusió, així com les seves mètriques corresponents. Amb aquesta profunditat s'aconsegueix un train accuracy del 0.995 i un test d'accuracy de 0.93. La matriu de confusió ens deixa veure que es classifiquen correctament 58 tumors malignes i 101 benignes, i 6 malignes són classificats com a benignes, i 6 benignes com a malignes. Per tant, amb tota aquesta informació veiem un bon rendiment global tot i que es pot millorar.\n",
    "\n",
    "En conseqüència, acabem de veure que a vegades limitar la profunditat de l'arbre a valors intermedis és una bona opció que permet deixar el model equilibrat amb capacitat de generalització."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04583f1-6e4c-4282-97f8-6e654b2da80d",
   "metadata": {},
   "source": [
    "### Exercici 4: Comparació de criteris de divisió: Gini vs Entropia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dcd0a37-75d6-4852-a269-74b31bc7980c",
   "metadata": {},
   "source": [
    "1. Utilitza el mateix train/test split de l'Exercici 3.\n",
    "2. Entrena un arbre amb:\n",
    "- Model G: DecisionTreeClassifier(criterion=\"gini\", max_depth=best_depth, random_state=RANDOM_STATE)\n",
    "- Model E: DecisionTreeClassifier(criterion=\"entropy\", max_depth=best_depth, random_state=RANDOM_STATE) (pots reutilitzar best_depth de l'Exercici 3 o triar un valor raonable, per exemple max_depth=4).\n",
    "3. Calcula l'accuracy en train i en test per a cada model.\n",
    "4. Mostra la confusion_matrix dels dos models.\n",
    "5. Comenta si hi ha diferències importants entre Gini i Entropia en aquest cas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6232a97-37c4-4031-8221-b3a69a8e9b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Profunditat òptima trobada abans\n",
    "best_depth = 5\n",
    "\n",
    "# Model G (criteri Gini)\n",
    "tree_g = DecisionTreeClassifier(\n",
    "    criterion=\"gini\",\n",
    "    max_depth=best_depth,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "tree_g.fit(X_train, y_train)\n",
    "\n",
    "# Model E (criteri Entropia)\n",
    "tree_e = DecisionTreeClassifier(\n",
    "    criterion=\"entropy\",\n",
    "    max_depth=best_depth,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "tree_e.fit(X_train, y_train)\n",
    "\n",
    "print(\"MODEL G\")\n",
    "print(\"Train accuracy:\", tree_g.score(X_train, y_train))\n",
    "print(\"Test accuracy :\", tree_g.score(X_test, y_test))\n",
    "\n",
    "print(\"\\nMODEL E\")\n",
    "print(\"Train accuracy:\", tree_e.score(X_train, y_train))\n",
    "print(\"Test accuracy :\", tree_e.score(X_test, y_test))\n",
    "\n",
    "# Prediccions\n",
    "y_pred_g = tree_g.predict(X_test)\n",
    "y_pred_e = tree_e.predict(X_test)\n",
    "\n",
    "# Matriu de confussió del model G\n",
    "cm_g = confusion_matrix(y_test, y_pred_g)\n",
    "disp_g = ConfusionMatrixDisplay(confusion_matrix=cm_g, display_labels=cancer.target_names)\n",
    "disp_g.plot(cmap=\"Blues\")\n",
    "plt.title(f\"Matriu de confusió del Model G (Gini, depth={best_depth})\")\n",
    "plt.show()\n",
    "\n",
    "# Ara la del model E\n",
    "cm_e = confusion_matrix(y_test, y_pred_e)\n",
    "disp_e = ConfusionMatrixDisplay(confusion_matrix=cm_e, display_labels=cancer.target_names)\n",
    "disp_e.plot(cmap=\"Blues\")\n",
    "plt.title(f\"Matriu de confusió del Model E (Entropia, depth={best_depth})\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50786d13-de6c-4288-96ef-449340907cb3",
   "metadata": {},
   "source": [
    "Ara, amb el mateix train/test split d'abans en el que havíem trobat que la millor profunditat era 5, s'han entrenat dos arbres, un amb el criteri Gini i l'altre amb l'Entropia, s'ha calculat l'accuracy en train i test, i s'han obtingut les matrius de confusions de cada model.\n",
    "\n",
    "Els resultats mostren que tenen un comportament molt similar. L'accuracy en train és aproximadament de 0.995 en els dos models, però en accuracy en test sí que canvia una mica, en el cas del criteri Gini, tenim un accuracy de 0.93 i en Entropia de 0.95, veient així que el criteri Entropia té una millor capacitat de generalització.\n",
    "\n",
    "Amb les matrius de confusió reforcem aquesta idea, en el Model E s'han obtingut 8 errors en total, mentre que en el model G s'han trobat 12 errors, per tant, el model E és lleugerament millor, ja que redueix els falsos positius i falsos negatius. Tot i així tenim un bon rendiment i molt similar en ambdós casos.\n",
    "\n",
    "Com a resultat, amb aquesta profunditat i aquest dataset, podem dir que amb els dos criteris de divisió, obtenim molt bons resultats i un bon rendiment, però que el criteri d'Entropia dona millor capacitat de generalització, per tant és lleugerament millor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f9b33f-c389-4569-844d-2039c88d4021",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
